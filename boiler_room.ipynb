{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import googleapiclient.discovery\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient import channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtubeAPIkey = \"AIzaSyBiZNzj3_RsALj0JfLnsA24j7VkGxjXagM\"\n",
    "youtube = build('youtube','v3',developerKey=youtubeAPIkey)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get all playlists from boilerroom in 2022, lets grab the list= from the playlist url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_playlists = []\n",
    "\n",
    "channel_id = 'UCGBpxWJr9FNOcFYA5GkKrMg'\n",
    "\n",
    "request = youtube.playlists().list(\n",
    "    part = 'snippet,contentDetails',\n",
    "    channelId = channel_id,\n",
    "    maxResults = 50\n",
    "    \n",
    ")\n",
    "response = request.execute()\n",
    "for r in response['items']: ## iterating inside the response part of the json object\n",
    "    playlist_dict = {\n",
    "    'playlist_id' : r['id'],\n",
    "    'publish_date': r['snippet']['publishedAt'],\n",
    "    'playlist_title': r['snippet']['title'],\n",
    "    }\n",
    "    \n",
    "    br_playlists.append(playlist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = []\n",
    "request = youtube.playlists().list(\n",
    "    part = \"snippet\",\n",
    "    channelId = channel_id,\n",
    "    maxResults = 50\n",
    ")\n",
    "response = request.execute()\n",
    "## by testing if the request we're making is not invalid (aka None), we continue the While loop to retrieve all playlist info from the Boiler Room channel\n",
    "## a for loop won't work straight since the maxResults param is capped at 50 requests. \n",
    "## https://stackoverflow.com/questions/62347194/youtube-api-get-all-playlist-id-from-a-channel-python\n",
    "\n",
    "playlists = []\n",
    "while request is not None: \n",
    "    response = request.execute()\n",
    "    playlists += response[\"items\"]\n",
    "    request = youtube.playlists().list_next(request, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_ids = []\n",
    "for playlist in playlists: ## iterating inside the response part of the json object\n",
    "    playlist_dict = {\n",
    "    'playlist_id' : playlist['id'],\n",
    "    'publish_date': playlist['snippet']['publishedAt'],\n",
    "    'playlist_title': playlist['snippet']['title'],\n",
    "    }\n",
    "    playlists_ids.append(playlist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of playlists retrieved:',len(playlists_ids))\n",
    "playlists_ids[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've retrieved the playlist_ids, we can loop through them to get the actual video_ids inside that playlist. But first, let's make sure that we are are looking for only 2022 playlists"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep only 2022 playlists from Boiler Room. For that, a dict comprehension works: we will filter each item in the playlist_ids list if the first four digits of the publish_date value is equal to 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_ids_2022 = [d for d in playlists_ids if d['publish_date'][:4] == '2022']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of playlists retrieved:',len(playlists_ids_2022))\n",
    "playlists_ids_2022[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(playlists_ids_2022)/len(playlists_ids))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the 62 playlists uploaded during 2022 by Boiler Room - almost 12% of all uploads of the channel since 2013! Looks like people were looking to party after the pandemic."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets get the video ids per playlist. To do so, we will use the same logic of while loops to get all video info from the playlists, then add it as a dictionary item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_playlist_id = [d['playlist_id'] for d in playlists_ids_2022] ##dict comprehension to get a list of the playlist_ids, saving us of a nested for loop\n",
    "\n",
    "video_list = [] ## list to nest the results\n",
    "for pl_id in list_playlist_id:\n",
    "    request = youtube.playlistItems().list(\n",
    "    part = \"snippet\",\n",
    "    playlistId = pl_id,\n",
    "    maxResults = 50\n",
    "    )\n",
    "    while request is not None: \n",
    "        response = request.execute()\n",
    "        video_list += response[\"items\"]\n",
    "        request = youtube.playlists().list_next(request, response)\n",
    "\n",
    "video_list_compact = []\n",
    "for video in video_list: ## iterating inside the response part of the json object\n",
    "    video_dict = {\n",
    "    'playlist_id': video['snippet']['playlistId'],\n",
    "    'video_id' : video['snippet']['resourceId']['videoId'],\n",
    "    'video_title': video['snippet']['title'],\n",
    "    'video_desc': video['snippet']['description'],\n",
    "    }\n",
    "    video_list_compact.append(video_dict)\n",
    "\n",
    "print(len(video_list_compact))\n",
    "video_list_compact[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list_compact[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We now have 418 videos to look in the comments for a video tracklist.\n",
    "\n",
    "Usually *users* post the full tracklist of the set, including unreleasead remixes and bootlegs, which are not supported by the Youtube tracklist due to copyrights - which is completelly understandable. So, we will map each video and look in the top comments for the video tracklist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_video_id = [d['video_id'] for d in video_list_compact]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_list = []\n",
    "for video_id in list_video_id:\n",
    "    request_c = youtube.commentThreads().list(\n",
    "    part = \"snippet\",\n",
    "    videoId = video_id,\n",
    "    # moderationStatus = 'published',\n",
    "    order = 'relevance',\n",
    "    maxResults = 20,\n",
    "    searchTerms = 'tracklist|play|songs',\n",
    "    textFormat = 'plainText'\n",
    "    )\n",
    "    while request_c is not None: \n",
    "        response_c = request_c.execute()\n",
    "        comments_list += response_c[\"items\"]['snippet']\n",
    "        request = youtube.playlists().list_next(request, response)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boilerroom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81dfef01605805e27f0ba6883a8d22b988fa50bff668fd7ed19a157fc0ad2d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
